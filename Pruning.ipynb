{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vgg11(nn.Module):\n",
    "    def __init__(self,cfg, init_weights=True):\n",
    "        super(Vgg11, self).__init__()\n",
    "       \n",
    "        self.cfg = cfg\n",
    "        self.feature = self.make_layers(self.cfg, True)\n",
    "\n",
    "        self.num_classes = 10\n",
    "        self.classifier =  nn.Linear(self.cfg[-1], 10)\n",
    "\n",
    "\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def make_layers(self, cfg, batch_norm=False):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1, bias=False)\n",
    "                if batch_norm:\n",
    "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                else:\n",
    "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        x = nn.AvgPool2d(2)(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(0.5)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vgg11(\n",
       "  (feature): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU(inplace=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oricfg =  [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512]\n",
    "vgg11 = Vgg11(oricfg)\n",
    "\n",
    "resume = False\n",
    "if resume:\n",
    "    checkpoint = torch.load('./vgg11.pth')\n",
    "    model_dict = vgg11.state_dict()\n",
    "    pretrained_dict = {k: v for k, v in checkpoint['net'].items() if k in model_dict  }\n",
    "    model_dict.update(pretrained_dict)\n",
    "    vgg11.load_state_dict(model_dict)\n",
    "vgg11.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data/', train=True, download=False,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Pad(4),\n",
    "                           transforms.RandomCrop(32),\n",
    "                           transforms.RandomHorizontalFlip(),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                       ])),\n",
    "        batch_size=batchsize, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data/', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                       ])),\n",
    "        batch_size=batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test :  Accuracy: 5671/10000 (56.71%)\n",
      "\n",
      "Test :  Accuracy: 6265/10000 (62.65%)\n",
      "\n",
      "Test :  Accuracy: 6750/10000 (67.50%)\n",
      "\n",
      "Test :  Accuracy: 7006/10000 (70.06%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(vgg11.parameters(), lr=1e-4)\n",
    "\n",
    "s = 0.0001\n",
    "\n",
    "def updateBN():\n",
    "    for m in vgg11.modules():\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.grad.data.add_(s*torch.sign(m.weight.data))  # L1\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    vgg11.train()\n",
    " #   prbar = tqdm(total=len(train_loader))\n",
    " #   prbar.set_description(\"training epoch\"+str(epoch))\n",
    "    for data, target in train_loader:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output =  F.softmax(vgg11(data),dim=-1)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        updateBN()\n",
    "        optimizer.step()\n",
    "        \n",
    "   #     prbar.update(1)\n",
    "  #      prbar.set_postfix(loss=loss.item())\n",
    "  #  prbar.close()\n",
    "    \n",
    "def test(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            output = F.softmax(model(data),dim=-1)\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    print('Test :  Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "for epoch in range(0,100):\n",
    "    train(epoch)\n",
    "    test(vgg11)\n",
    "    if epoch %10 == 1:\n",
    "        torch.save({'net':vgg11.state_dict(), 'optimizer':optimizer.state_dict(), 'epoch':epoch},'./vgg11.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for m in vgg11.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        total += m.weight.data.shape[0]\n",
    "bn = torch.zeros(total)\n",
    "index = 0\n",
    "for m in vgg11.modules():\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        size = m.weight.data.shape[0]\n",
    "        bn[index:(index+size)] = m.weight.data.abs().clone()\n",
    "        index += size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent = 0.5\n",
    "y, i = torch.sort(bn)\n",
    "thre_index = int(total * percent)\n",
    "thre = y[thre_index]\n",
    "print(\"'gamma' less than {} is thrown away\".format(thre.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned = 0\n",
    "cfg = []\n",
    "cfg_mask = []\n",
    "\n",
    "\n",
    "for k, m in enumerate(vgg11.modules()):\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        weight_copy = m.weight.data.clone()\n",
    "        mask = weight_copy.abs().gt(thre).float().cuda()\n",
    "        pruned = pruned + mask.shape[0] - torch.sum(mask)\n",
    "      #  m.weight.data.mul_(mask)\n",
    "     #   m.bias.data.mul_(mask)\n",
    "        cfg.append(int(torch.sum(mask)))\n",
    "        cfg_mask.append(mask.clone())\n",
    "        print('layer index: {:d} \\t total channel: {:d} \\t remaining channel: {:d}'.\n",
    "            format(k, mask.shape[0], int(torch.sum(mask))))\n",
    "    elif isinstance(m, nn.MaxPool2d):\n",
    "        cfg.append('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newvgg11 = Vgg11(cfg)\n",
    "newvgg11.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_id_in_cfg = 0\n",
    "start_mask = torch.ones(3)\n",
    "end_mask = cfg_mask[layer_id_in_cfg]\n",
    "for [m0, m1] in zip(vgg11.modules(), newvgg11.modules()):\n",
    "    if isinstance(m0, nn.BatchNorm2d):\n",
    "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "        m1.weight.data = m0.weight.data[idx1].clone()\n",
    "        m1.bias.data = m0.bias.data[idx1].clone()\n",
    "        m1.running_mean = m0.running_mean[idx1].clone()\n",
    "        m1.running_var = m0.running_var[idx1].clone()\n",
    "       \n",
    "        layer_id_in_cfg += 1\n",
    "        start_mask = end_mask.clone()\n",
    "        if layer_id_in_cfg < len(cfg_mask):  # do not change in Final FC\n",
    "            end_mask = cfg_mask[layer_id_in_cfg]\n",
    "    elif isinstance(m0, nn.Conv2d):\n",
    "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "        idx1 = np.squeeze(np.argwhere(np.asarray(end_mask.cpu().numpy())))\n",
    "        print('In shape: {:d} Out shape:{:d}'.format(idx0.shape[0], idx1.shape[0]))\n",
    "        w = m0.weight.data[:, idx0, :, :].clone()\n",
    "        w = w[idx1, :, :, :].clone()\n",
    "        m1.weight.data = w.clone()\n",
    "        \n",
    "     #   m1.bias.data = m0.bias.data[idx1].clone() # In some conv layers there is no bias.\n",
    "    elif isinstance(m0, nn.Linear):\n",
    "        idx0 = np.squeeze(np.argwhere(np.asarray(start_mask.cpu().numpy())))\n",
    "        m1.weight.data = m0.weight.data[:, idx0].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(newvgg11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
